{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST/t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Restoring parameters from AE_model/AE_model\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "plt.ioff()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Parameters for user to set\n",
    "testing_batch_size = 64\n",
    "epochs = 10\n",
    "plot_rows = 4 # num of test image rows to run and plot\n",
    "plot_cols = 6 # ditto (cols must be even)\n",
    "add_skip_connect = False # if true will learn ID function in like 2 epochs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Getting the MNIST data set and logging its parameters\n",
    "data = input_data.read_data_sets('data/MNIST', one_hot=True)\n",
    "img_size = 28\n",
    "img_size_flat = img_size*img_size\n",
    "img_shape = (img_size, img_size)\n",
    "num_channels_x = 1\n",
    "training_size = len(data.train.labels)\n",
    "\n",
    "\n",
    "\n",
    "session = tf.Session()\n",
    "\n",
    "saver = tf.train.import_meta_graph('AE_model/AE_model.meta')\n",
    "saver.restore(session, tf.train.latest_checkpoint('AE_model'))\n",
    "\n",
    "\n",
    "graph = tf.get_default_graph()\n",
    "x = graph.get_tensor_by_name('x:0')\n",
    "\n",
    "output_layer = graph.get_tensor_by_name('output_layer:0')\n",
    "conv_layer_1 = graph.get_tensor_by_name('conv_layer_1:0')\n",
    "conv_layer_2 = graph.get_tensor_by_name('conv_layer_2:0')\n",
    "conv_layer_3 = graph.get_tensor_by_name('conv_layer_3:0')\n",
    "\n",
    "\n",
    "# Run the learned network on testing data\n",
    "flat_imgs,_ = data.test.next_batch(testing_batch_size)\n",
    "imgs = flat_imgs.reshape((-1,img_size,img_size,1))\n",
    "feed_dict = {x: imgs}\n",
    "[imgs_recon, layer_3_imgs] = session.run([output_layer, conv_layer_3], feed_dict)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Show original images and reconstructed images\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "for i in range(1,plot_rows*plot_cols+1):\n",
    "    if(i%2==1):\n",
    "        fig.add_subplot(plot_rows,plot_cols,i)\n",
    "        plt.imshow(imgs[i-1,:,:,0],cmap='gray')\n",
    "    else:\n",
    "        fig.add_subplot(plot_rows,plot_cols,i)\n",
    "        plt.imshow(layer_3_imgs[i-2,:,:,1], cmap='gray')\n",
    "\n",
    "plt.savefig('sample_encodings.png')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
